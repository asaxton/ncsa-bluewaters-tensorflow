#!/bin/bash
#PBS -l nodes=4:ppn=32:xe+16:ppn=16:xk
##PBS -l nodes=10:ppn=16:xk
#PBS -l walltime=10:00:00
#PBS -N inception_imagenet_distributed_train
#PBS -e logs/log.${PBS_JOBNAME}_NN_${PBS_NUM_NODES}_${PBS_JOBID}.err
#PBS -o logs/log.${PBS_JOBNAME}_NN_${PBS_NUM_NODES}_${PBS_JOBID}.out

echo "Starting"
cd $PBS_O_WORKDIR
mkdir -p logs

NUM_GPU=$(aprun -n ${PBS_NUM_NODES} -N 1 -- /sbin/lspci | grep NVIDIA | wc -l)
let NUM_PS=${PBS_NUM_NODES}-${NUM_GPU}
NUM_WORKER=${NUM_GPU}
if [ "${NUM_PS}" -eq '0' ];
then
echo "all nodes have a GPU, giving some of them to the PS"
NUM_PS=$((${NUM_GPU}/4))
NUM_WORKER=$((${PBS_NUM_NODES}-${NUM_PS}))
fi

echo "NUM_PS ${NUM_PS}, NUM_WORKER ${NUM_WORKER}"

module load bwpy
module load bwpy-mpi

MBS=32
NUM_STEPS=$(echo "${NUM_TRAINING_EXAMPLES}*${NUM_EPOCHS} / ( ${MBS} )" | bc )
# NUM_STEPS=38545500 # 3200 epochs at batchsize 1
# NUM_STEPS=1204500 # 100 epochs at batch size 32
NUM_STEPS=300 # 0 epochs for testing
DATA_DIR="${HOME}/scratch/ImageNet/tf_records"

#UNIQUE_CHECKPOINT_NAME="_$(cat /dev/urandom | tr -dc 'A-Z0-9' | fold -w 3 | head -n 1)"

LEARNING_RATE=$(echo "0.4 * sqrt(${NUM_WORKER})" | bc)
echo "Learning Rate: ${LEARNING_RATE}"

APOUT_LOGS="${PBS_O_WORKDIR}/logs/apout.${PBS_JOBNAME}_NW_${NUM_WORKER}_MBS_${MBS}_${PBS_JOBID}"
CHECKPT_DIR="checkpoint_dir_${PBS_JOBNAME}_${PBS_JOBID}"

echo "output at ${APOUT_LOGS}.*"
echo "checkpoint_dir at ${CHECKPT_DIR}"

RUN_CMD="python ${PBS_O_WORKDIR}/../BWDistributedTrain/inception_imagenet_distributed_train.py \
--data_dir $DATA_DIR/train \
--num_steps $NUM_STEPS \
--num_train_examples 385455 \
--batch_size ${MBS} \
--initial_learning_rate ${LEARNING_RATE} \
--checkpoint_dir ${CHECKPT_DIR}"
echo "Running Comand"
echo ${RUN_CMD}
aprun -b -cc none -n ${NUM_PS} -N 1 $RUN_CMD --ps_worker ps : -n ${NUM_WORKER} -N 1 $RUN_CMD --ps_worker worker \
1> ${APOUT_LOGS}.out \
2> ${APOUT_LOGS}.err

echo "Done, Thank you for flying."
